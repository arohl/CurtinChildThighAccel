{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters for notebook so can easily change as right at top of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of windows in seconds\n",
    "window_size = 5\n",
    "\n",
    "# accelerometer to be analysed; valid values are 'acg', 'axivity' and 'sens'\n",
    "accelerometer = \"sens\"\n",
    "\n",
    "# label defining the motus labels to include in the analysis - used in filenames of output data\n",
    "include = \"all\"\n",
    "\n",
    "drop_impure=True\n",
    "\n",
    "# select MOTUS values to keep. NotRecording should never be kept. Have some defaults but can choose explicitly\n",
    "if include == \"sit_stand\":\n",
    "    values_to_keep = [\"Sit\", \"Stand\"]\n",
    "elif include == \"all\":\n",
    "    values_to_keep = [\"Lie\", \"Sit\", \"Stand\", \"Walk\", \"Stairs\", \"Run\", \"Other\"]\n",
    "else:\n",
    "    values_to_keep = [\"Sit\", \"Stand\"]\n",
    "\n",
    "all_values = [\"Unknown\", \"Other\", \"Lie\", \"Sit\", \"Stand\", \"Walk\", \"Stairs\", \"Run\"]\n",
    "# all_values = [\"Lie\", \"Sit\", \"Stand\", \"Walk\", \"Stairs\", \"Run\"]\n",
    "values_to_drop = [value for value in all_values if value not in values_to_keep]\n",
    "\n",
    "DATA_DIR = \"./data\"  # data\n",
    "JSON_DIR = \"../machine_learning/\"\n",
    "\n",
    "dl_normalisation_method = \"min_max\" # std_dev OR min_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "from eval_metrics import eval_classification\n",
    "\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_colwidth = None\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if accelerometer == \"acg\":\n",
    "    ACC_MISSING = [23, 24, 25, 34, 36]\n",
    "elif accelerometer == \"axivity\":\n",
    "    raise Exception(\"Axivity data not tested yet\")\n",
    "elif accelerometer == \"sens\":\n",
    "    ACC_MISSING = []\n",
    "else:\n",
    "    raise Exception(\"Invalid accelerometer type\")\n",
    "\n",
    "acc_missing = [f\"P{i:02d}.csv.gz\" for i in ACC_MISSING]\n",
    "\n",
    "\n",
    "def load_all_and_make_windows(datafiles):\n",
    "    def worker(datafile):\n",
    "        print(\"\\nProcessing\", datafile)\n",
    "        data = utils.load_data(datafile, acc_prefix=accelerometer)\n",
    "        data = utils.map_to_new_classes(\n",
    "            data, \"annotation\", JSON_DIR + \"motus_class_map.json\", verbose=True\n",
    "        )\n",
    "        data = data[~data[\"annotation\"].isin(values_to_drop)]\n",
    "        X, Y, T = utils.make_windows(\n",
    "            data,\n",
    "            winsec=window_size,\n",
    "            sample_rate=30,\n",
    "            dropna=False,\n",
    "            drop_impure=drop_impure,\n",
    "            verbose=True,\n",
    "            frame_info= True,\n",
    "        )\n",
    "        pid = os.path.basename(datafile).split(\".\")[0]  # participant ID\n",
    "        pid = np.asarray([pid] * len(X))\n",
    "        return X, Y, T, pid\n",
    "\n",
    "    results = []\n",
    "    for datafile in tqdm(datafiles):\n",
    "        if os.path.basename(datafile) in acc_missing:\n",
    "            print(\"\\nSkipping\", datafile)\n",
    "            continue\n",
    "        result = worker(datafile)\n",
    "        results.append(result)\n",
    "\n",
    "    X = np.concatenate([result[0] for result in results])\n",
    "    Y = np.concatenate([result[1] for result in results])\n",
    "    T = np.concatenate([result[2] for result in results])\n",
    "    pid = np.concatenate([result[3] for result in results])\n",
    "\n",
    "    return X, Y, T, pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original labels\n",
    "original_labels = [\"Lie\", \"Sit\", \"Stand\", \"Walk\", \"Stairs\", \"Run\"]\n",
    "\n",
    "# Manually create a mapping between labels and their corresponding encoded values\n",
    "label_mapping = {label: index for index, label in enumerate(original_labels)}\n",
    "\n",
    "# Convert the list to a numpy array\n",
    "original_labels = np.array(original_labels)\n",
    "\n",
    "# Create an instance of LabelEncoder with the specified mapping\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.classes_ = original_labels\n",
    "label_encoder.transform(\n",
    "    original_labels\n",
    ")  # This step is important to set internal state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data, map to motus, make windows and output to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if data directory exists\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    # raise an error\n",
    "    raise Exception(\n",
    "        \"Data directory does not exist. Please create it and download the data.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles = os.path.join(DATA_DIR, \"P*/cleaned_data_*_30hz_v1.1.csv\")\n",
    "X_train, y_train, T, pid = load_all_and_make_windows(sorted(glob(datafiles)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's count the number of window_size windows for each activity class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLabel distribution (# windows)\")\n",
    "print(pd.Series(y_train).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove NA or nan data\n",
    "indices_to_keep = ~np.logical_or(y_train == \"nan\", y_train == \"Other\")\n",
    "# Use boolean indexing to get the filtered arrays\n",
    "X_train = X_train[indices_to_keep]\n",
    "y_train = y_train[indices_to_keep]\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] * 3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load unseen data for Leave One Subject Out (LOSO) evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSO_DATA_DIR = \"./data/LOSO\"\n",
    "\n",
    "datafiles_evl = os.path.join(LOSO_DATA_DIR, \"P*/cleaned_data_*_30hz_v1.1.csv\")\n",
    "X_test, y_test, T_evl, pid_evl = load_all_and_make_windows(sorted(glob(datafiles_evl)))\n",
    "# Find indices where y is not equal to \"nan\"\n",
    "indices_to_keep_evl = ~np.logical_or(y_test == \"nan\", y_test == \"Other\")\n",
    "\n",
    "# Filter X and y based on the indices\n",
    "X_test = X_test[indices_to_keep_evl]\n",
    "y_test = y_test[indices_to_keep_evl]\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1] * 3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation\n",
    "Let's visualise some examples for each activity label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPLOTS = 8\n",
    "unqY = np.unique(Y)\n",
    "fig, axs = plt.subplots(\n",
    "    len(unqY), NPLOTS, sharex=True, sharey=True, figsize=(NPLOTS * 1.5, len(unqY) + 1)\n",
    ")\n",
    "for y, row in zip(unqY, axs):\n",
    "    idxs = np.random.choice(np.where(Y == y)[0], size=NPLOTS)\n",
    "    if y == \"Throwing and catching\":\n",
    "        y = \"T&C\"\n",
    "    elif y == \"Walking downstairs\":\n",
    "        y = \"W downstairs\"\n",
    "    elif y == \"Walking upstairs\":\n",
    "        y = \"W upstairs\"\n",
    "    elif y == \"Running upstairs\":\n",
    "        y = \"R upstairs\"\n",
    "    row[0].set_ylabel(y)\n",
    "    for x, ax in zip(X[idxs], row):\n",
    "        ax.plot(x[:, 0], color=\"red\")\n",
    "        ax.plot(x[:, 1], color=\"green\")\n",
    "        ax.plot(x[:, 2], color=\"blue\")\n",
    "        ax.set_ylim(-5, 5)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the labels\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `dl_normalisation_method` is defined earlier\n",
    "if dl_normalisation_method == \"std_dev\":\n",
    "    mean_value = np.mean(X_train)\n",
    "    std_value = np.std(X_train)\n",
    "\n",
    "    X_train = (X_train - mean_value) / std_value\n",
    "    X_test = (X_test - mean_value) / std_value\n",
    "    params_file = 'normalization_params_std_dev.pkl'\n",
    "    if not os.path.exists(params_file):\n",
    "        # Save normalization parameters\n",
    "        joblib.dump({'mean': mean_value, 'std': std_value}, params_file)\n",
    "\n",
    "elif dl_normalisation_method == \"min_max\":\n",
    "    min_vals = np.min(X_train, axis=0)\n",
    "    max_vals = np.max(X_train, axis=0)\n",
    "\n",
    "    # Perform Min-Max scaling\n",
    "    X_train = (X_train - min_vals) / (max_vals - min_vals)\n",
    "    X_test = (X_test - min_vals) / (max_vals - min_vals)\n",
    "\n",
    "    params_file = 'normalization_params_min_max.pkl'\n",
    "    if not os.path.exists(params_file):\n",
    "        # Save normalization parameters\n",
    "        joblib.dump({'min': min_vals, 'max': max_vals}, params_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up learning rate parameters\n",
    "lr_params = {\"learning_rate\": 0.001, \"decay_steps\": 1000, \"decay_rate\": 0.95}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"input_shape\": (X_train.shape[1], X_train.shape[2]),\n",
    "    \"num_classes\": len(np.unique(y_train)),\n",
    "    \"lr_params\": lr_params,\n",
    "    \"loss_func\": \"sparse_categorical_crossentropy\",\n",
    "}\n",
    "model_struc = {\n",
    "    \"conv1d_layers\": {\n",
    "        \"parameters\": [\n",
    "            {\"filters\": 64, \"kernel_size\": 7},\n",
    "            {\"filters\": 128, \"kernel_size\": 7},\n",
    "        ],\n",
    "    },\n",
    "    \"lstm_layers\": {\n",
    "        \"parameters\": [\n",
    "            {\"units\": 128},\n",
    "            {\"units\": 64},\n",
    "        ],\n",
    "    },\n",
    "    \"dense_layers\": {\n",
    "        \"parameters\": [\n",
    "            {\"units\": 128, \"reg_rate\": 0.01, \"dropout_rate\": 0.5},\n",
    "            {\"units\": 64, \"reg_rate\": 0.01, \"dropout_rate\": 0.5},\n",
    "        ],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_lstm_model_creator import CreateCNNLSTM\n",
    "\n",
    "model_creator = CreateCNNLSTM(config=config)\n",
    "model = model_creator.create_model(model_struc=model_struc)\n",
    "model = model_creator.compile_model(model=model)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights based on the label set\n",
    "class_counts = np.bincount(y_train)\n",
    "total_samples = np.sum(class_counts)\n",
    "class_weights = total_samples / (len(class_counts) * class_counts)\n",
    "\n",
    "# Set the class weights for specific classes to 1\n",
    "classes_to_ignore = []  # Replace with the classes you want to ignore\n",
    "class_weights[classes_to_ignore] = 1\n",
    "\n",
    "# Create a dictionary to store the class weights\n",
    "class_weights_dict = dict(enumerate(class_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=10, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=1000,\n",
    "    validation_data=(X_test, y_test),\n",
    "    class_weight=class_weights_dict,\n",
    "    callbacks=[early_stopping],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Evaluation\n",
    "loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_encoded = np.argmax(y_pred, axis=1) if y_pred.ndim > 1 else y_pred\n",
    "y_pred_decoded = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "utils.plot_confusion_matrix(y_test, y_pred, label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_metrics import eval_classification\n",
    "\n",
    "metrics_df = eval_classification(y_test, y_pred_decoded)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import save_model, load_model\n",
    "\n",
    "# Save the model\n",
    "save_model(model, \"lstm_cnn_model.h5\")\n",
    "\n",
    "# Load the model\n",
    "loaded_model = load_model(\"lstm_cnn_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the loaded model\n",
    "loss, accuracy = loaded_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blind Test on Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load blind test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles_blind = [\"./file1.csv\", \"./file2.csv\"]\n",
    "X_blind, y_blind, T_blind, pid_blind = load_all_and_make_windows(sorted(glob(datafiles_blind)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove NA or nan data\n",
    "indices_to_keep_blind = ~np.logical_or(y_blind == \"nan\", y_blind == \"Other\")\n",
    "# Use boolean indexing to get the filtered arrays\n",
    "X_blind = X_blind[indices_to_keep_blind]\n",
    "y_blind = y_blind[indices_to_keep_blind]\n",
    "X_blind = X_blind.reshape(X_blind.shape[0], X_blind.shape[1] * 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the normalization parameters\n",
    "if dl_normalisation_method == \"std_dev\":\n",
    "    params = joblib.load('normalization_params_std_dev.pkl')\n",
    "    mean_value = params['mean']\n",
    "    std_value = params['std']\n",
    "\n",
    "    X_blind = (X_blind - mean_value) / std_value\n",
    "\n",
    "elif dl_normalisation_method == \"min_max\":\n",
    "    params = joblib.load('normalization_params_min_max.pkl')\n",
    "    min_vals = params['min']\n",
    "    max_vals = params['max']\n",
    "\n",
    "    X_blind = (X_blind - min_vals) / (max_vals - min_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_blind = label_encoder.transform(y_blind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_dir = \"./trained_models/lstm_cnn_model_3_mm_pure_5s.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(trained_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_blind)\n",
    "\n",
    "utils.plot_confusion_matrix(y_blind, y_pred, label_encoder, original_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_encoded = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = eval_classification(y_blind, y_pred_encoded)\n",
    "metrics_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "9a3b77c227d1fbdef124e225713923a56e39b7d0c2b2917b161700591669ab26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
